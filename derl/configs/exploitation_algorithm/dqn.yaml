# @package _group_
_target_: off_policy.algos.dqn.DQN
model:
  architecture: default # 'default' or 'dueling'
  hiddens:
    - 64
    - 64
  advantage:
    - 32 # populated for dueling architecture with ints
  value:
    - 32 # populated for dueling architecture with ints
  activation: 'relu' # options: 'relu' or 'tanh'
  device: cpu

replay_buffer:
  type: default # 'default' or 'prioritised'
  prioritised_increment_epsilon: 1e-10 # priority increment epsilon
  prioritised_exponent_alpha: 0.6 # priority exponent alpha

# number of updates of behavioural policy at which the exploitation algorithm is updated
update_freq: 1

targets: double # 'default' or 'double'
lr: 1e-3
tau: 0.001
batch_size: 1024
buffer_capacity: 1e5
n_steps: 5
kl_coef: 0.0

eps_start: 1.0
eps_end: 0.05
eps_decay: 2.5e+5
greedy_epsilon: 0.00

max_grad_norm: 0.5
adam_eps: 0.001
gamma: 0.99
use_proper_time_limits: false